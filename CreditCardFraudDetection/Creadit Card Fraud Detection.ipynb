{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2efbd48-3b47-4c3b-b571-37ef82a91156",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+-------------------+----------------+------------------+-------------------+-------------------+-------------------+------------------+------------------+-------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+-------------------+------------------+-------------------+--------------------+-------------------+------------------+------------------+------------------+------------------+--------------------+-------------------+------+-----+\n|Time|                V1|                 V2|              V3|                V4|                 V5|                 V6|                 V7|                V8|                V9|                V10|               V11|               V12|               V13|               V14|               V15|               V16|               V17|                V18|               V19|                V20|                 V21|                V22|               V23|               V24|               V25|               V26|                 V27|                V28|Amount|Class|\n+----+------------------+-------------------+----------------+------------------+-------------------+-------------------+-------------------+------------------+------------------+-------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+-------------------+------------------+-------------------+--------------------+-------------------+------------------+------------------+------------------+------------------+--------------------+-------------------+------+-----+\n| 0.0|  -1.3598071336738|-0.0727811733098497|2.53634673796914|  1.37815522427443| -0.338320769942518|  0.462387777762292|  0.239598554061257|0.0986979012610507| 0.363786969611213| 0.0907941719789316|-0.551599533260813|-0.617800855762348|-0.991389847235408|-0.311169353699879|  1.46817697209427|-0.470400525259478| 0.207971241929242| 0.0257905801985591| 0.403992960255733|  0.251412098239705|  -0.018306777944153|  0.277837575558899|-0.110473910188767|0.0669280749146731| 0.128539358273528|-0.189114843888824|   0.133558376740387|-0.0210530534538215|149.62|    0|\n| 0.0|  1.19185711131486|   0.26615071205963|0.16648011335321| 0.448154078460911| 0.0600176492822243|-0.0823608088155687|-0.0788029833323113|0.0851016549148104|-0.255425128109186| -0.166974414004614|  1.61272666105479|  1.06523531137287|  0.48909501589608|-0.143772296441519| 0.635558093258208| 0.463917041022171|-0.114804663102346| -0.183361270123994|-0.145783041325259|-0.0690831352230203|  -0.225775248033138| -0.638671952771851| 0.101288021253234|-0.339846475529127| 0.167170404418143| 0.125894532368176|-0.00898309914322813| 0.0147241691924927|  2.69|    0|\n| 1.0| -1.35835406159823|  -1.34016307473609|1.77320934263119| 0.379779593034328| -0.503198133318193|   1.80049938079263|  0.791460956450422| 0.247675786588991| -1.51465432260583|  0.207642865216696| 0.624501459424895| 0.066083685268831| 0.717292731410831|-0.165945922763554|  2.34586494901581| -2.89008319444231|  1.10996937869599| -0.121359313195888| -2.26185709530414|  0.524979725224404|   0.247998153469754|  0.771679401917229| 0.909412262347719|-0.689280956490685|-0.327641833735251|-0.139096571514147| -0.0553527940384261|-0.0597518405929204|378.66|    0|\n| 1.0|-0.966271711572087| -0.185226008082898|1.79299333957872|-0.863291275036453|-0.0103088796030823|   1.24720316752486|   0.23760893977178| 0.377435874652262| -1.38702406270197|-0.0549519224713749|-0.226487263835401| 0.178228225877303| 0.507756869957169| -0.28792374549456|-0.631418117709045|  -1.0596472454325|-0.684092786345479|   1.96577500349538|  -1.2326219700892| -0.208037781160366|  -0.108300452035545|0.00527359678253453|-0.190320518742841| -1.17557533186321| 0.647376034602038|-0.221928844458407|  0.0627228487293033| 0.0614576285006353| 123.5|    0|\n| 2.0| -1.15823309349523|  0.877736754848451|  1.548717846511| 0.403033933955121| -0.407193377311653| 0.0959214624684256|  0.592940745385545|-0.270532677192282| 0.817739308235294|  0.753074431976354|-0.822842877946363|  0.53819555014995|   1.3458515932154| -1.11966983471731| 0.175121130008994|-0.451449182813529|-0.237033239362776|-0.0381947870352842| 0.803486924960175|  0.408542360392758|-0.00943069713232919|   0.79827849458971|-0.137458079619063| 0.141266983824769|-0.206009587619756| 0.502292224181569|   0.219422229513348|  0.215153147499206| 69.99|    0|\n+----+------------------+-------------------+----------------+------------------+-------------------+-------------------+-------------------+------------------+------------------+-------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+-------------------+------------------+-------------------+--------------------+-------------------+------------------+------------------+------------------+------------------+--------------------+-------------------+------+-----+\nonly showing top 5 rows\n\n+-----+------+\n|Class| count|\n+-----+------+\n|    1|   492|\n|    0|284315|\n+-----+------+\n\n1003\nOut[4]: '\\n# Split data into training and testing sets (80% train, 20% test)\\ntrain_data, test_data = balanced_df.randomSplit([0.8, 0.2], seed=42)\\n\\n\\n# Train Decision Tree model\\ndt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\")\\nmodel = dt.fit(train_data)\\n\\n\\n# Print the decision tree structure\\nprint(\"Learned classification tree model:\")\\nprint(model.toDebugString)\\n\\n\\n# Make predictions on test data\\npredictions = model.transform(test_data)\\n\\n\\n# Display sample predictions\\npredictions.select(\"features\", \"label\", \"prediction\").show(5)\\n\\n\\n# Evaluate using AUC (Better for fraud detection)\\nevaluator = BinaryClassificationEvaluator(labelCol=\"label\", metricName=\"areaUnderROC\")\\nauc = evaluator.evaluate(predictions)\\n\\n\\n# Print AUC Score\\nprint(f\"AUC Score: {auc:.2f}\")'"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"CreditCardFraudDetection\").getOrCreate()\n",
    "\n",
    "# Load dataset \n",
    "df = spark.read.csv(\"dbfs:/FileStore/shared_uploads/vidhikarayate@gmail.com/creditcard.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Display first few rows\n",
    "df.show(5)\n",
    "#df.printSchema()\n",
    "\n",
    "# Check class imbalance (Count fraud vs non-fraud cases)\n",
    "df.groupBy(\"Class\").count().show()\n",
    "\n",
    "# Convert class label to \"label\" column (Required by Spark ML)\n",
    "indexer = StringIndexer(inputCol=\"Class\", outputCol=\"label\")\n",
    "df = indexer.fit(df).transform(df)\n",
    "\n",
    "\n",
    "# Select features (excluding \"Class\")\n",
    "feature_columns = [col for col in df.columns if col not in [\"Class\", \"label\"]]\n",
    "\n",
    "\n",
    "# Assemble features into a single feature vector\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "df = assembler.transform(df).select(\"features\", \"label\")\n",
    "\n",
    "\n",
    "\n",
    "# Handle class imbalance using **Undersampling**\n",
    "fraud_cases = df.filter(col(\"label\") == 1.0)\n",
    "non_fraud_cases = df.filter(col(\"label\") == 0.0)\n",
    "\n",
    "\n",
    "# Get the count of fraud cases\n",
    "fraud_count = fraud_cases.count()\n",
    "\n",
    "\n",
    "# Undersample the majority class (non-fraud) to match fraud cases\n",
    "non_fraud_sample = non_fraud_cases.sample(withReplacement=False, fraction=fraud_count / non_fraud_cases.count())\n",
    "\n",
    "# Combine fraud and undersampled non-fraud cases\n",
    "balanced_df = fraud_cases.union(non_fraud_sample)\n",
    "print(balanced_df.count())\n",
    "\n",
    "\n",
    "# Split data into training and testing sets (80% train, 20% test)\n",
    "train_data, test_data = balanced_df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "\n",
    "# Train Decision Tree model\n",
    "dt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "model = dt.fit(train_data)\n",
    "\n",
    "\n",
    "# Print the decision tree structure\n",
    "print(\"Learned classification tree model:\")\n",
    "print(model.toDebugString)\n",
    "\n",
    "\n",
    "# Make predictions on test data\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "\n",
    "# Display sample predictions\n",
    "predictions.select(\"features\", \"label\", \"prediction\").show(5)\n",
    "\n",
    "\n",
    "# Evaluate using AUC (Better for fraud detection)\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"label\", metricName=\"areaUnderROC\")\n",
    "auc = evaluator.evaluate(predictions)\n",
    "\n",
    "\n",
    "# Print AUC Score\n",
    "print(f\"AUC Score: {auc:.2f}\")"
   ]
  }
 ],
 
